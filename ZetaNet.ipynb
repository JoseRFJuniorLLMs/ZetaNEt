{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9BTYuyeuCuv"
      },
      "outputs": [],
      "source": [
        "https://www-users.cse.umn.edu/~odlyzko/zeta_tables/index.html\n",
        "https://github.com/JoseRFJuniorLLMs/ZetaNet\n",
        "https://www-users.cse.umn.edu/~odlyzko/zeta_tables/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/riemann_zeta\n",
        "!git init\n",
        "!git remote add origin https://huggingface.co/JoseRFJunior/ZetaNet\n"
      ],
      "metadata": {
        "id": "7i6xlKXifUJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Função para limpar e formatar strings complexas\n",
        "def parse_complex(value):\n",
        "    value = value.strip()\n",
        "    if 'j' not in value:\n",
        "        value += 'j'\n",
        "    value = value.replace(',', '.')\n",
        "    value = value.replace('(', '').replace(')', '')\n",
        "    try:\n",
        "        return complex(value)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "# Definindo a arquitetura da rede neural usando PyTorch\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
        "            if i < len(layer_sizes) - 2:\n",
        "                layers.append(nn.BatchNorm1d(layer_sizes[i + 1]))  # Adicionando BatchNorm\n",
        "                layers.append(nn.ReLU())\n",
        "                layers.append(nn.Dropout(p=0.3))  # Dropout para regularização\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Função para calcular o erro quadrático médio\n",
        "def mean_squared_error(predictions, targets):\n",
        "    return nn.MSELoss()(predictions, targets)\n",
        "\n",
        "# Função para treinar o modelo\n",
        "def train_model(model, x_train, y_train, x_val, y_val, learning_rate, epochs):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)  # Scheduler para reduzir LR\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(x_train)\n",
        "        loss = criterion(predictions, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Ajustar a taxa de aprendizado\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            val_predictions = model(x_val)\n",
        "            val_loss = criterion(val_predictions, y_val)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    start_time = time()\n",
        "\n",
        "    # Carregar dados\n",
        "    data = pd.read_csv(\"/content/combined_zeta_data.csv\")\n",
        "\n",
        "    # Limpar e formatar dados complexos\n",
        "    data['s'] = data['s'].apply(parse_complex)\n",
        "    data['zeta(s)'] = data['zeta(s)'].apply(parse_complex)\n",
        "\n",
        "    # Verificar valores inválidos após a conversão\n",
        "    if data['s'].isnull().any() or data['zeta(s)'].isnull().any():\n",
        "        print(\"Erro: Valores inválidos encontrados após a conversão.\")\n",
        "        return\n",
        "\n",
        "    # Separar parte real e imaginária\n",
        "    data['s_real'] = data['s'].apply(lambda x: x.real)\n",
        "    data['s_imag'] = data['s'].apply(lambda x: x.imag)\n",
        "    data['zeta_real'] = data['zeta(s)'].apply(lambda x: x.real)\n",
        "    data['zeta_imag'] = data['zeta(s)'].apply(lambda x: x.imag)\n",
        "\n",
        "    # Converter para tensores\n",
        "    x_data = torch.tensor(data[['s_real', 's_imag']].values, dtype=torch.float32)\n",
        "    y_data = torch.tensor(data[['zeta_real', 'zeta_imag']].values, dtype=torch.float32)\n",
        "\n",
        "    # Normalizar dados\n",
        "    x_mean = x_data.mean(dim=0)\n",
        "    x_std = x_data.std(dim=0)\n",
        "    y_mean = y_data.mean(dim=0)\n",
        "    y_std = y_data.std(dim=0)\n",
        "    x_std[x_std == 0] = 1  # Evitar divisão por zero\n",
        "    y_std[y_std == 0] = 1  # Evitar divisão por zero\n",
        "    x_data = (x_data - x_mean) / x_std\n",
        "    y_data = (y_data - y_mean) / y_std\n",
        "\n",
        "    # Dividir os dados em conjuntos de treinamento e validação\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar e treinar o modelo\n",
        "    architectures = [\n",
        "        [2, 64, 64, 32, 2],    # Arquitetura 1\n",
        "        [2, 128, 128, 64, 2],  # Arquitetura 2\n",
        "        [2, 256, 128, 64, 32, 2]  # Arquitetura 3\n",
        "    ]\n",
        "    best_model = None\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for arch in architectures:\n",
        "        print(f\"Treinando com arquitetura: {arch}\")\n",
        "        model = NeuralNetwork(arch)\n",
        "        train_model(model, x_train, y_train, x_val, y_val, learning_rate=0.001, epochs=200)\n",
        "\n",
        "        # Avaliar o modelo\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(x_val)\n",
        "            val_loss = mean_squared_error(val_predictions, y_val).item()\n",
        "            print(f\"Val Loss com arquitetura {arch}: {val_loss}\")\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model\n",
        "\n",
        "    print(\"Melhor modelo encontrado com Val Loss:\", best_val_loss)\n",
        "\n",
        "    # Salvar o melhor modelo\n",
        "    model_path = '/content/riemann_zeta_best_model.pth'\n",
        "    torch.save(best_model.state_dict(), model_path)\n",
        "\n",
        "    # Denormalizar previsões para plotagem\n",
        "    with torch.no_grad():\n",
        "        denorm_predictions = best_model(x_val) * y_std + y_mean\n",
        "\n",
        "    # Plotar resultados\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(data['s_real'], data['s_imag'], color='blue', label='Real', alpha=0.5)\n",
        "    plt.scatter(denorm_predictions[:, 0], denorm_predictions[:, 1], color='red', label='Previsto', alpha=0.5)\n",
        "    plt.xlabel('Parte Real')\n",
        "    plt.ylabel('Parte Imaginária')\n",
        "    plt.title('Função Zeta de Riemann: Real vs Previsto')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/riemann_zeta_best_plot.png')\n",
        "    plt.show()  # Exibe o gráfico diretamente se estiver usando um notebook\n",
        "\n",
        "    end_time = time()\n",
        "    print(\"Tempo de execução:\", (end_time - start_time), \"segundos\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "h2eDfQRxoFG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "id": "464CUYD0gDCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Substitua pelo seu token do Hugging Face\n",
        "login(token=\"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\")\n"
      ],
      "metadata": {
        "id": "vJk6J7u6gQTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fc_BJlWHdpI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "W4eNc_hGkE3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, upload_file\n",
        "\n",
        "# Substitua pelo seu token de autenticação\n",
        "token = \"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\"\n",
        "\n",
        "# Autenticar com o Hugging Face\n",
        "login(token=token)\n",
        "\n",
        "# Definir o caminho dos arquivos a serem enviados\n",
        "model_file_path = '/content/riemann_zeta.pth'\n",
        "plot_file_path = '/content/riemann_zeta_plot_pytorch.png'\n",
        "repo_id = \"JoseRFJunior/ZetaNet\"\n",
        "\n",
        "# Fazer upload dos arquivos\n",
        "upload_file(path_or_fileobj=model_file_path, path_in_repo='riemann_zeta.pth', repo_id=repo_id, token=token)\n",
        "upload_file(path_or_fileobj=plot_file_path, path_in_repo='riemann_zeta_plot_pytorch.png', repo_id=repo_id, token=token)\n",
        "\n",
        "print(\"Arquivos enviados com sucesso!\")\n"
      ],
      "metadata": {
        "id": "mKHYGwldkato"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}